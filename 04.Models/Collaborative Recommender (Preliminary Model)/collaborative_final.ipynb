{"cells":[{"cell_type":"markdown","metadata":{"id":"oSkyK2IsuqNl"},"source":["## Set Up"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4063,"status":"ok","timestamp":1688047499710,"user":{"displayName":"Beatriz Leitao","userId":"00922298846450358063"},"user_tz":-120},"id":"DnZAe-CVuqNp","outputId":"1d801b99-c673-4575-b1b4-382bc4c2e973"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import datetime\n","from scipy.sparse import csc_matrix\n","from scipy.sparse import load_npz\n","from sklearn.metrics.pairwise import cosine_similarity\n","from gensim.models import KeyedVectors\n","from gensim.models import Word2Vec\n","import nltk\n","from nltk.corpus import stopwords\n","import heapq\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","pd.set_option('display.max_colwidth', None)\n","import json\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","source":["# Function to select multiple user IDs & timestamps for evaluation\n","def select_user_ids_timestamps(k=5):\n","  # Select the top 10 rows\n","  filtered_behaviors_df = behaviors_df.tail(k)\n","\n","  # Create a list of tuples containing values from columns 'a' and 'b'\n","  user_ids_timestamps = [(row['User ID'], row['Timestamp']) for _, row in filtered_behaviors_df.iterrows()]\n","\n","  return user_ids_timestamps"],"metadata":{"id":"7mrNpiOtNvU0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"85PgkxPTuqNr"},"source":["## Import Data\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M8Ww33DFuqNr","executionInfo":{"status":"ok","timestamp":1688047545056,"user_tz":-120,"elapsed":45352,"user":{"displayName":"Beatriz Leitao","userId":"00922298846450358063"}},"outputId":"127b5cb4-4529-4a7e-94e9-47a7bf487f9d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# import news df\n","news_df = pd.read_pickle(\"/content/drive/MyDrive/Group_19/01.Dataset/Small/Clean/Train/news.pkl\")\n","\n","# import behaviors df\n","behaviors_df = pd.read_pickle(\"/content/drive/MyDrive/Group_19/01.Dataset/Small/Clean/Train/behaviors.pkl\")"]},{"cell_type":"markdown","source":["# Collaborative Model\n"],"metadata":{"id":"hxB0QzDoiQKo"}},{"cell_type":"markdown","metadata":{"id":"4CKAv7qduqNt"},"source":["## Define Functions for User to User Collaborative Filtering"]},{"cell_type":"code","source":["def fetch_similar_users(user_id, timestamp, k=5):\n","  # Get IDs in user's history\n","  presiouvly_read_article_ids = (\n","      list(\n","          behaviors_df.loc[\n","              ((behaviors_df['User ID'] == user_id) & (behaviors_df['Timestamp'] == timestamp)),\n","              'History'\n","          ].str.split()\n","      )[0]\n","  )\n","\n","  # Get average vector of user's history news IDs\n","  average_user_vector = news_df.loc[news_df['News ID'].isin(presiouvly_read_article_ids), 'Average Vector'].mean()\n","\n","  # Create a copy of behaviours_df\n","  user_similarity_df = behaviors_df.copy()\n","  user_similarity_df = user_similarity_df.dropna()\n","\n","  # Filter out input user from user_similarity_df\n","  user_similarity_df = user_similarity_df.loc[user_similarity_df['User ID'] != user_id]\n","\n","  # Drop duplicate users\n","  user_similarity_df = user_similarity_df.drop_duplicates(subset=['User ID', 'History & Impressions'])\n","\n","  # Compute cosine similarity between average_news_vector and each unread news article\n","  user_similarity_df['Similarity'] = user_similarity_df['Average Vector'].apply(lambda x: cosine_similarity([average_user_vector], [x])[0][0])\n","\n","  # Sort dataframe in descending order\n","  user_similarity_df = user_similarity_df.sort_values(by='Similarity', ascending=False).head(k)\n","\n","  # Get similar users\n","  similar_users_timestamps = [(row['User ID'], row['Timestamp']) for _, row in user_similarity_df.iterrows()]\n","\n","  return similar_users_timestamps"],"metadata":{"id":"dNNlt9zUzvTd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def recommend_articles_collaborative(user_id, timestamp, similar_users_timestamps, k=5):\n","  # Filter behaviors df for similar users & timestamps\n","  similar_users_df = behaviors_df[behaviors_df[['User ID', 'Timestamp']].apply(tuple, axis=1).isin(similar_users_timestamps)]\n","\n","  # Initialize list to store relevant article IDs\n","  recommended_article_ids = []\n","\n","  # Iterate over the rows of the DataFrame\n","  for index, row in similar_users_df.iterrows():\n","    # Split the text into words and add them to the word_list\n","    recommended_article_ids.extend(row['History & Impressions'].split())\n","\n","  # Get IDs in user's history\n","  previously_read_article_ids = (\n","      list(\n","          behaviors_df.loc[\n","              ((behaviors_df['User ID'] == user_id) & (behaviors_df['Timestamp'] == timestamp)),\n","              'History'\n","          ].str.split()\n","      )[0]\n","  )\n","\n","  # Remove any already read articles from the recommended articles\n","  recommended_article_ids = list(set([id for id in recommended_article_ids if id not in previously_read_article_ids]))\n","  recommended_article_ids = recommended_article_ids[:k]\n","\n","  return recommended_article_ids"],"metadata":{"id":"LfVNjJrm3Bmb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K9v6AABOuqNv"},"source":["## Define Functions that consolidate Pipeline"]},{"cell_type":"markdown","metadata":{"id":"cARuG1m6uqNv"},"source":["### Single User"]},{"cell_type":"code","source":["def single_user_recommendations_collaborative(user_id, timestamp, similar_user_k=5, articles_k=5):\n","\n","  # Get user ID & time stamp of similar user interactions\n","  similar_users_timestamps = fetch_similar_users(user_id, timestamp, k=similar_user_k)\n","\n","  # Get article IDs read by similar user interactions\n","  recommended_article_ids = recommend_articles_collaborative(user_id, timestamp, similar_users_timestamps, k=articles_k)\n","\n","  return recommended_article_ids"],"metadata":{"id":"1kFAbfvqJMEy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YLdgvwoQuqNv"},"source":["### Multiple Users"]},{"cell_type":"code","source":["def multiple_user_recommendations_collaborative(user_ids_timestamps, similar_user_k=5, articles_k=5):\n","\n","  # Create empty dictionary to store recommendations\n","  user_recommendations_dict = {}\n","\n","  # Keep track of how many iterations have run\n","  counter = 0\n","\n","  # Iterate over users & timestamps\n","  for user_id, timestamp in user_ids_timestamps:\n","    # Update counter\n","    counter += 1\n","    # Run function for single user recommendation\n","    single_user_recommendations_collaborative(user_id, timestamp, similar_user_k=similar_user_k, articles_k=articles_k)\n","\n","    # create dictionary entry for recommendation\n","    user_recommendations_dict[user_id] = final_recommended_ids\n","\n","  return user_recommendations_dict"],"metadata":{"id":"3lHdtvGIG_pY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r4FmCwhYuqNw"},"source":["## Test on Sample User"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJkO1IPEuqNw"},"outputs":[],"source":[" # Run recommender system\n","final_recommended_ids = single_user_recommendations_collaborative('U13740', '2019-11-13 15:27:40', similar_user_k=5, articles_k=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1688047594269,"user":{"displayName":"Beatriz Leitao","userId":"00922298846450358063"},"user_tz":-120},"id":"omG4By0ZuqNw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c8feb2da-3b82-4656-c165-21b0b54dfc58"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['N27919', 'N48076', 'N47765', 'N9317', 'N38367']"]},"metadata":{},"execution_count":9}],"source":["# view recommendations - avg vec\n","final_recommended_ids"]},{"cell_type":"markdown","metadata":{"id":"DBQLjSrBuqNw"},"source":["## Test on Multiple Users"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hWGIbcoguqNx"},"outputs":[],"source":["# Select a subset of users of size k to test on\n","user_ids_timestamps = select_user_ids_timestamps(k=5)\n","\n","# Run recommender system\n","final_recommended_ids_multiple = multiple_user_recommendations_collaborative(user_ids_timestamps, similar_user_k=5, articles_k=5)"]},{"cell_type":"code","source":["final_recommended_ids_multiple"],"metadata":{"id":"fQUKyYT5s_J0","executionInfo":{"status":"ok","timestamp":1688047834529,"user_tz":-120,"elapsed":29,"user":{"displayName":"Beatriz Leitao","userId":"00922298846450358063"}},"outputId":"6edfa260-4ea4-427e-bf93-1d461b526ddf","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'U21593': ['N27919', 'N48076', 'N47765', 'N9317', 'N38367'],\n"," 'U10123': ['N27919', 'N48076', 'N47765', 'N9317', 'N38367'],\n"," 'U75630': ['N27919', 'N48076', 'N47765', 'N9317', 'N38367'],\n"," 'U44625': ['N27919', 'N48076', 'N47765', 'N9317', 'N38367'],\n"," 'U64800': ['N27919', 'N48076', 'N47765', 'N9317', 'N38367']}"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["### Export recommendations for evaluation"],"metadata":{"id":"4sfVXusR64VY"}},{"cell_type":"code","source":["with open('/content/drive/MyDrive/Group_19/01.Dataset/Predictions/predictions_collaborative.json', 'w') as json_file:\n","    json.dump(final_recommended_ids_multiple, json_file)"],"metadata":{"id":"PRX2qkFW3pBN"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}